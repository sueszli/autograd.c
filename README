$ toilet -f mono12 -w 100 "autograd.c"
                                                                             ▄▄                     
                       ██                                                    ██                     
  ▄█████▄  ██    ██  ███████    ▄████▄    ▄███▄██   ██▄████   ▄█████▄   ▄███▄██       ▄█████▄ 
  ▀ ▄▄▄██  ██    ██    ██      ██▀  ▀██  ██▀  ▀██   ██▀       ▀ ▄▄▄██  ██▀  ▀██      ██▀    ▀ 
 ▄██▀▀▀██  ██    ██    ██      ██    ██  ██    ██   ██       ▄██▀▀▀██  ██    ██      ██       
 ██▄▄▄███  ██▄▄▄███    ██▄▄▄   ▀██▄▄██▀  ▀██▄▄███   ██       ██▄▄▄███  ▀██▄▄███  ██  ▀██▄▄▄▄█ 
  ▀▀▀▀ ▀▀   ▀▀▀▀ ▀▀     ▀▀▀▀     ▀▀▀▀     ▄▀▀▀ ██   ▀▀        ▀▀▀▀ ▀▀    ▀▀▀ ▀▀  ▀▀    ▀▀▀▀▀  
                                          ▀████▀▀                                                   

$ make run

    ...

$ cat references.txt

    - https://github.com/harvard-edge/cs249r_book/blob/dev/tinytorch/src/






TODO:

simplify convolutions.c
use forward and backward in main and see if it leaks

decouple ops from tensors


- autograd.c -> improve code quality based on @CONTRIBUTING.md
    - make backward functions for everything - ie. activations_backward, tensors_backward, losses_backward, etc.
- training.c -> https://github.com/harvard-edge/cs249r_book/blob/dev/tinytorch/src/07_training/ABOUT.md
- test_e2e.c
- benchmarking and visualizing, finishing readme
