todo:

make sure main.c runs
make sure all tests run

- study ops.c/h
    - move `shapes_match` to broadcast.c/h - expose it through api, test it rigourously
    - add all the missing operations in a modern neural net
- study tensor.c/h and autograd.c/h

issues:

- "Fake" Batching: The training loop in main.c simulates batching by accumulating gradients over several samples before updating the weights. A true PyTorch-style implementation would collate the batch of inputs into a single, higher-dimensional tensor (e.g., shape [32, 3072]) and perform a single forward and backward pass on the entire batch. The current method is computationally different and much slower, though the gradient accumulation achieves a similar result for SGD.

finally:

- implement a python binding just for predictions
